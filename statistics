cd("C:/Users/Matt/Desktop/Julia files")

using Pkg
Pkg.add("StatsBase")
Pkg.add("Gadfly")
Pkg.add("HypothesisTests")
# other plotting packages in Python are Plotly and Bokeh
# other plotting packages in Julia are Winston and Vega

using CSV
X = CSV.read("magic04.csv")
N, n = size(X) # Get the dimensions of the X Array (N = rows / data points, n = columns / features)
# split data into input (I) and output (O) arrays
I = Array{Float64}(undef,N, n-1)
O = X[:, end]
for j = 1:(n-1)
    for i = 1:N
        I[i,j] = Float64(X[i,j]) # Transform the data in the X Array into Floats
    end
end

# variable summary
describe(X)
for i = 1:size(I,2)
    describe(I[:,i])
end

# summary stats
Pkg.add("StatsBase")
using StatsBase
summarystats(I[:,1]).mean

# Pearson correlation coefficient
cor(I)
# Spearman's rank correlation: http://bit.ly/29mcSwn
# Kandell's tau rank correlation: http://bit.ly/29pJztd
# Similarity Index, Simple Matching Coefficient, or the Jaccard Coefficient can also be used here.

# prepare data for plotting
# Gadfly doesn't like arrays, so create a list of variable names for referencing
varnames = ["fLength", "fWidth", "fSize", "fConc","fConc1", "fAsym", "fM3Long", "fM3Trans","fAlpha", "fDist","class"]
# bind everything in a data frame
df = CSV.read("magic04.csv") # read in data as data frame
old_names = names(df)
new_names = [Symbol(varnames[i]) for i = 1:length(varnames)] # create array containing symbol equivalent of variable names from varnames
for i = 1:length(old_names)
    rename!(df, old_names[i], new_names[i]) # change names of df to those in arraynames
end

# bar plot using Gadfly
using Gadfly
plot(df, x = "class", Geom.bar, Guide.ylabel("count"), Guide.title("Class distribution for Magic dataset"))

# line plot using Gadfly
plot(df, y = "fSize", Geom.line, Guide.xlabel("data point"), Guide.ylabel("fSize"), Guide.title("fSize of various data points in Magic dataset"))

# scatterplot using Gadfly
plot(x = df[:fM3Long], y = df[:fM3Trans], Geom.point, Guide.xlabel("fM3Long"), Guide.ylabel("fM3Trans"), Guide.title("Relationship between fM3Trans & fM3Long"))
# Scatter plots using the output of t-SNE algorithm -- Laurens van der Maaten
Pkg.clone("git://github.com/lejon/TSne.jl.git") # this mapping method takes multi-dimensional feature space and reduces it to 1, 2, or 3 dimensions.
using TSne
include("normalize.jl")
include("sample.jl")
X = normalize(X, "stat")
X, O = sample(X, O, 2000)
Y = tsne(X, 2)
plot(x = Y[:,1], y = Y[:,2], color = O)

# histogram using Gadfly
p = plot(x = df[:fAlpha], Geom.histogram(bincount=20), Guide.xlabel("fAplha"), Guide.ylabel("frequency"))

# export a plot to a file
Pkg.add("Cairo")
using Cairo
myplot = plot(x = [1,2,3,4,5], y = [2,3.5,7,7.5,10])
draw(PNG("myplot.png", 5inch, 2.5inch), myplot)
draw(PDF("myplot.png", 10cm, 5cm), myplot)


# hypothesis testing
# t-test
pvalue(EqualVarianceTTest(x, y)) # equal variance between variables
pvalue(UnequalVarianceTTest(x, y)) # unequal variance between variables
# chi-square test
ChisqTest(X)


# example using OnlineNewsPopularity dataset
df = readtable(“OnlineNewsPopularity.csv”, header = true)
# descriptive stats
Z = names(df)[2:end] # Exclude the first column of the data frame (url) as it is both non-numeric and irrelevant
for z in Z
    X = convert(Array, df[symbol(z)]);
    println(z, “\t”, summarystats(X))
end
# normalize values
for z in Z
    X = df[symbol(z)]
    Y = (X - mean(X)) / std(X) # equivalent to normalize(X, “stat”)
    df[symbol(z)] = Y
end
# determine correlations
n = length(Z)
C = Array(Any, n, 2)
for i = 1:n
    X = df[symbol(Z[i])]
    C[i,1] = Z[i][2:end]
    C[i,2] = cor(X, df[:shares])
end
# visualize
for i = 1:n
    plot(x = df[symbol(Z[i])],
    Geom.histogram, Guide.xlabel(string(Z[i])),
    Guide.ylabel(“frequency”))
    plot(x = df[symbol(Z[i])], y = df[:shares],
    Geom.point, Guide.xlabel(string(Z[i])),
    Guide.ylabel(“shares”))
end
# hypothesis testing
a = 0.01 # Set the significance threshold (alpha value)
N = length(Y)
mY = mean(Y)
ind1 = (1:N)[Y .>= mY]
ind2 = (1:N)[Y .< mY]
A = Array(Any, 59, 4)
for i = 1:59
    X = convert(Array, df[symbol(Z[i])])
    X_high = X[ind1]
    X_low = X[ind2]
    var_high = var(X_high)
    var_low = var(X_low)
    if abs(2(var_high - var_low)/(var_high + var_low)) <= 0.1 # Check to see if variances are within 10% of each other (approximately)
        p = pvalue(EqualVarianceTTest(X_high,X_low))
    else
        p = pvalue(UnequalVarianceTTest(X_high,X_low))
end
A[i,:] = [i, Z[i], p, p < a]
if p < a
println([i, “\t”, Z[i]]) # Print variable number and name if it’s statistically significant
end
end
# conclusions
# 1. The distributions of most of the variables are balanced.
# 2. Normalizing the variables is imperative.
# 3. There is a weak linear relationship between each input variable and the target variable.
# 4. The inputs of the dataset can predict whether the target variable is generally high or low, with statistical significance (a = 0.01).
# 5. Using a scatter plot based on t-SNE, we can see that the relationship of all the input variables with the target variable is reversely proportional (albeit weakly).
